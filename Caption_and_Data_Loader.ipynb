{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN94lfg4RDDrItQeK2l4mo+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalDharpure/HateFul-Hindi-Memes-Detection/blob/main/Caption_and_Data_Loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApLk3tdqeScy"
      },
      "outputs": [],
      "source": [
        "pip install beautifulsoup4 requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def download_memes(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch content from {url}. Status code: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    image_tags = soup.find_all('img')\n",
        "\n",
        "    for idx, img_tag in enumerate(image_tags):\n",
        "        img_url = img_tag['src']\n",
        "        img_url = urljoin(url, img_url)\n",
        "        try:\n",
        "            img_response = requests.get(img_url, stream=True)\n",
        "            img_extension = img_url.split('.')[-1]\n",
        "\n",
        "            # Save the image to a file\n",
        "            file_name = f'meme_{idx}.{img_extension}'\n",
        "            with open(file_name, 'wb') as img_file:\n",
        "                for chunk in img_response.iter_content(chunk_size=8192):\n",
        "                    img_file.write(chunk)\n",
        "\n",
        "            print(f\"Downloaded {file_name} successfully.\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Failed to download image from {img_url}: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace this with the URL containing the memes you want to download\n",
        "    meme_url = \"https://imgflip.com/tag/hot+chick\"\n",
        "    download_memes(meme_url)\n"
      ],
      "metadata": {
        "id": "HdY3rjvPeVmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def download_memes(url):\n",
        "    # Create a 'data' directory if it doesn't exist\n",
        "    if not os.path.exists('data'):\n",
        "        os.makedirs('data')\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch content from {url}. Status code: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    image_tags = soup.find_all('img')\n",
        "\n",
        "    for idx, img_tag in enumerate(image_tags):\n",
        "        img_url = img_tag['src']\n",
        "        img_url = urljoin(url, img_url)\n",
        "        try:\n",
        "            img_response = requests.get(img_url, stream=True)\n",
        "            img_extension = img_url.split('.')[-1]\n",
        "\n",
        "            # Save the image to a file inside the 'data' folder\n",
        "            file_name = f'data/meme_{idx}.{img_extension}'\n",
        "            with open(file_name, 'wb') as img_file:\n",
        "                for chunk in img_response.iter_content(chunk_size=8192):\n",
        "                    img_file.write(chunk)\n",
        "\n",
        "            print(f\"Downloaded {file_name} successfully.\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Failed to download image from {img_url}: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace this with the URL containing the memes you want to download\n",
        "    meme_url = \"https://imgflip.com/tag/hot+chick\"\n",
        "    download_memes(meme_url)\n"
      ],
      "metadata": {
        "id": "PAsLGcEzezKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install easyocr"
      ],
      "metadata": {
        "id": "pRBvTmnEf5v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r4BU23Mff7JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tfV3VW6Rf5sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import easyocr\n",
        "\n",
        "# Function to extract captions using EasyOCR\n",
        "def extract_caption_using_easyocr(image_path):\n",
        "    # Initialize EasyOCR reader\n",
        "    reader = easyocr.Reader(['en'])\n",
        "\n",
        "    try:\n",
        "        # Extract text from the image\n",
        "        result = reader.readtext(image_path, detail=0)\n",
        "        caption = ' '.join(result)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract caption from {image_path}: {str(e)}\")\n",
        "        caption = \"Caption extraction failed.\"\n",
        "\n",
        "    return caption\n",
        "\n",
        "# Rest of the code remains unchanged\n",
        "\n",
        "def create_tsv_with_easyocr(directory):\n",
        "    rows = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(directory, filename)\n",
        "            caption = extract_caption_using_easyocr(image_path)\n",
        "            categories = categorize_meme(caption)\n",
        "            rows.append([filename] + list(categories.values()) + [caption])\n",
        "\n",
        "    # Write to TSV file\n",
        "    with open('memes_data_with_easyocr.tsv', 'w', newline='') as tsvfile:\n",
        "        writer = csv.writer(tsvfile, delimiter='\\t')\n",
        "        writer.writerow([\"file_name\", \"misogynous\", \"shaming\", \"stereotype\", \"objectification\", \"violence\", \"Text_Transcription\"])\n",
        "        writer.writerows(rows)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with the directory containing your meme images\n",
        "    meme_directory = \"/content/data\"\n",
        "    create_tsv_with_easyocr(meme_directory)\n"
      ],
      "metadata": {
        "id": "U5zr070fe8Ol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}